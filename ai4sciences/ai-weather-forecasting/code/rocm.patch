
### Copyright 2025 Advanced Micro Devices, Inc.  All rights reserved.
### Licensed under the Apache License, Version 2.0 (the "License");
### you may not use this file except in compliance with the License.
### You may obtain a copy of the License at
###      http://www.apache.org/licenses/LICENSE-2.0
### Unless required by applicable law or agreed to in writing, software
### distributed under the License is distributed on an "AS IS" BASIS,
### WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
### See the License for the specific language governing permissions and
### limitations under the License.
diff --git a/src/ai_models/model.py b/src/ai_models/model.py
index c15ac10..1cc5ea9 100644
--- a/src/ai_models/model.py
+++ b/src/ai_models/model.py
@@ -220,7 +220,7 @@ class Model:
 
         available_providers = ort.get_available_providers()
         providers = []
-        for n in ["CUDAExecutionProvider", "CPUExecutionProvider"]:
+        for n in [ "ROCMExecutionProvider", "CUDAExecutionProvider", "CPUExecutionProvider"]:
             if n in available_providers:
                 providers.append(n)
 
@@ -234,7 +234,7 @@ class Model:
             if ort.get_device() == "CPU":
                 raise RuntimeError("GPU is not available")
 
-            providers = ["CUDAExecutionProvider"]
+            providers = ["ROCMExecutionProvider", "CUDAExecutionProvider"]
 
         LOG.info("ONNXRuntime providers: %s", providers)
 
